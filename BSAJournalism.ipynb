{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3df4b25",
   "metadata": {},
   "source": [
    "# BSA Data Journalism Spring 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f32788a",
   "metadata": {},
   "source": [
    "## Data scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "621f9a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40f634a",
   "metadata": {},
   "source": [
    "Defining start/end year and finding viable urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8e479875",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_year = 2008\n",
    "end_year = 2023\n",
    "url_reference = \"https://www.basketball-reference.com/draft/\"\n",
    "# cols = ['pick_overall', 'team_id', 'player', 'college_name', 'seasons', 'g', 'mp', 'pts', 'trb', 'ast', 'fg_pct', 'fg3_pct', 'ft_pct', 'mp_per_g',\n",
    "#        'pts_per_g', 'trb_per_g', 'ast_per_g', 'ws', 'ws_per_48', 'bpm', 'vorp']\n",
    "dfDraftInfo : pd.DataFrame = None\n",
    "path = \"./data/draftdata.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3cfbb60",
   "metadata": {},
   "source": [
    "Table found on page html with id = \"stats\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ee31e222",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_table(soup: BeautifulSoup, year : int):\n",
    "    df_cur_yr = None\n",
    "    \n",
    "    table = soup.find('table', {'id': 'stats'})\n",
    "    \n",
    "    if table is not None:\n",
    "        rows = table.find_all('tr')\n",
    "\n",
    "        for row in rows:\n",
    "            data = row.find_all('td')\n",
    "\n",
    "            player_data_dict = {}\n",
    "            for d in data:\n",
    "                datatype = d.get('data-stat')\n",
    "\n",
    "                if datatype is not None:\n",
    "                    # get contents\n",
    "                    content = d.text.strip()\n",
    "                    player_data_dict[str(datatype)] = str(content)\n",
    "\n",
    "            # check for non empty row\n",
    "            if len(player_data_dict.keys()) != 0:\n",
    "                player_data_dict[\"year\"] = year\n",
    "                if df_cur_yr is not None:    \n",
    "                    # keep adding\n",
    "                    temp_df = pd.DataFrame([player_data_dict])\n",
    "                    df_cur_yr = pd.concat([df_cur_yr, temp_df], axis = 0)\n",
    "                    pass\n",
    "                else:\n",
    "                    # not empty\n",
    "                    df_cur_yr = pd.DataFrame([player_data_dict])\n",
    "                    pass\n",
    "\n",
    "    return df_cur_yr.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ff763f",
   "metadata": {},
   "source": [
    "Go through every year between the start_year and the end_year and save in a csv file so we don't need to run this more once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3e875044",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_draft(): \n",
    "    success = True\n",
    "\n",
    "    for year in range(start_year, end_year+1):\n",
    "        url = url_reference + \"NBA_\" + str(year) + \".html\"\n",
    "        response = requests.get(url)\n",
    "        print(year)\n",
    "\n",
    "        # successful get\n",
    "        if response.status_code == 200:\n",
    "            soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "            df = get_table(soup, year)\n",
    "            if dfDraftInfo is None:\n",
    "                dfDraftInfo = df\n",
    "            else:\n",
    "                dfDraftInfo = pd.concat([dfDraftInfo, df]).reset_index(drop = True)\n",
    "        else: \n",
    "            print(\"Unsuccessful Get request\")\n",
    "            success = False\n",
    "            break\n",
    "\n",
    "        # delay scraping\n",
    "        time.sleep(2)\n",
    "\n",
    "    # save data from scrape\n",
    "    if success:\n",
    "        dfDraftInfo.to_csv(path, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d21c3e0",
   "metadata": {},
   "source": [
    "### Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79b47b3",
   "metadata": {},
   "source": [
    "Filter the data, get rid of the NA rows (forfeited)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8879c5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_draft = pd.read_csv(path)\n",
    "df_draft = df_draft.dropna(subset=['pick_overall'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec6d9df",
   "metadata": {},
   "source": [
    "Filter so that only the lottery picks are in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "03e560de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_draft = df_draft[df_draft['pick_overall'] < 15]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5fab7c",
   "metadata": {},
   "source": [
    "### Get pre-NBA stats for CBB players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "babcea0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_reference = \"https://www.sports-reference.com/cbb/players/anthony-davis-5.html\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60406ace",
   "metadata": {},
   "source": [
    "Get the list of names of players in the dataframe that went to college with their corresponding colleges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2c09e867",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cbb_players():\n",
    "    df_cbb_players = df_draft.dropna(subset=['college_name'])\n",
    "    return df_cbb_players\n",
    "\n",
    "df_cbb_players = get_cbb_players()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f7efd9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import re\n",
    "\n",
    "def split_name(name : str):\n",
    "    def strip_non_alphanumeric(s):\n",
    "        pattern = re.compile(r'[\\W_]+')\n",
    "        return pattern.sub('', s)\n",
    "    \n",
    "    names = name.split(\" \")\n",
    "    first_name = names[0]\n",
    "    last_names = names[1:]\n",
    "\n",
    "    first_name = strip_non_alphanumeric(first_name)\n",
    "    last_names = [strip_non_alphanumeric(l).lower() for l in last_names]\n",
    "\n",
    "    return first_name.lower(), last_names\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c78870f",
   "metadata": {},
   "source": [
    "Players with more than one word last names, \n",
    "Otto ['Porter', 'Jr.']\n",
    "Dennis ['Smith', 'Jr.']\n",
    "Marvin ['Bagley', 'III']\n",
    "Jaren ['Jackson', 'Jr.']\n",
    "Wendell ['Carter', 'Jr.']\n",
    "Michael ['Porter', 'Jr.']\n",
    "Kira ['Lewis', 'Jr.']\n",
    "Jabari ['Smith', 'Jr.']\n",
    "Dereck ['Lively', 'II']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "596c9fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# links of players with last names that don't follow the pattern\n",
    "urls = {\n",
    "    \"otto\" : \"https://www.sports-reference.com/cbb/players/otto-porter-1.html\",\n",
    "    \"dennis\" : \"https://www.sports-reference.com/cbb/players/dennis-smithjr-1.html\",\n",
    "    \"marvin\" : \"https://www.sports-reference.com/cbb/players/marvin-bagleyiii-1.html\",\n",
    "    \"jaren\" : \"https://www.sports-reference.com/cbb/players/jaren-jacksonjr-1.html\",\n",
    "    \"wendell\" : \"https://www.sports-reference.com/cbb/players/wendell-carterjr-1.html\",\n",
    "    \"michael\" : \"https://www.sports-reference.com/cbb/players/michael-porterjr-1.html\",\n",
    "    \"kira\" : \"https://www.sports-reference.com/cbb/players/kira-lewisjr-1.html\",\n",
    "    \"jabari\" : \"https://www.sports-reference.com/cbb/players/jabari-smith-2.html\",\n",
    "    \"dereck\" :  \"https://www.sports-reference.com/cbb/players/dereck-lively-ii-1.html\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b5b75e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cbb_stats : pd.DataFrame = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "39b07e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_helper(url : str):\n",
    "    df : pd.DataFrame = None\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        table = soup.find('table', {'id': 'players_per_game'})\n",
    "\n",
    "        if table is not None:\n",
    "            rows = table.find_all('tr')\n",
    "\n",
    "            for row in rows:\n",
    "                data = row.find_all('td')\n",
    "\n",
    "                player_data_dict = {}\n",
    "                for d in data:\n",
    "                    datatype = d.get('data-stat')\n",
    "\n",
    "                    if datatype is not None:\n",
    "                        # get contents\n",
    "                        content = d.text.strip()\n",
    "                        player_data_dict[str(datatype)] = str(content)\n",
    "\n",
    "        df = pd.DataFrame([player_data_dict])\n",
    "    else:\n",
    "        print(\"Bad Response Status Code\", response.status_code)\n",
    "        return None\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "eea58089",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_cbb_stats():\n",
    "    df_all : pd.DataFrame = None\n",
    "\n",
    "    for index, row in df_cbb_players.iterrows():\n",
    "        name = row['player']\n",
    "        team = row['college_name']\n",
    "\n",
    "        first_name, last_name = split_name(name)\n",
    "        \n",
    "        url = \"\"\n",
    "        if len(last_name) != 1:\n",
    "            url = urls[first_name]\n",
    "        else: \n",
    "            last_name = last_name[0]\n",
    "            for i in range(1, 10):\n",
    "                attempts = 0\n",
    "                while attempts < 3:\n",
    "                    # to check for the correct player (by team), for example anthony-davis-5, not anthony-davis-4\n",
    "                    url = f\"https://www.sports-reference.com/cbb/players/{first_name}-{last_name}-{i}.html\"\n",
    "                    print(url)\n",
    "                    response = requests.get(url)\n",
    "                    correct_url = False\n",
    "                    \n",
    "                    if response.status_code == 200:\n",
    "                        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "                        school_name_elements = soup.find_all(attrs={\"data-stat\": \"school_name\"})\n",
    "\n",
    "                        correct_url = any(team in element.get_text() for element in school_name_elements)\n",
    "                    else:\n",
    "                        print(\"Bad Response Status Code\", response.status_code)\n",
    "                        time.sleep(2)\n",
    "                        attempts += 1\n",
    "                        \n",
    "                    if correct_url:\n",
    "                        break\n",
    "                    else:\n",
    "                        time.sleep(2)\n",
    "        \n",
    "        if len(url) != 0:\n",
    "            df = scrape_helper(url)\n",
    "            while df is None:\n",
    "                time.sleep(2)\n",
    "                df = scrape_helper(url)\n",
    "            \n",
    "            if df_all is None:\n",
    "                df_all = df\n",
    "            else: \n",
    "                df_all = pd.concat([df_all, df]).reset_index(drop = True)\n",
    "        else:\n",
    "            print(\"URL not found\")\n",
    "        time.sleep(5)\n",
    "\n",
    "    return df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "466e5aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.sports-reference.com/cbb/players/derrick-rose-1.html\n",
      "Bad Response Status Code 429\n",
      "Bad Response Status Code 429\n",
      "Bad Response Status Code 429\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_cbb_stats \u001b[38;5;241m=\u001b[39m \u001b[43mscrape_cbb_stats\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m path2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./data/cbbdata.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      3\u001b[0m df_cbb_stats\u001b[38;5;241m.\u001b[39mto_csv(path2, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[43], line 39\u001b[0m, in \u001b[0;36mscrape_cbb_stats\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m df \u001b[38;5;241m=\u001b[39m scrape_helper(url)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m df \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 39\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m     df \u001b[38;5;241m=\u001b[39m scrape_helper(url)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m df_all \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df_cbb_stats = scrape_cbb_stats()\n",
    "path2 = './data/cbbdata.csv'\n",
    "df_cbb_stats.to_csv(path2, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638073a0",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'head'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mdf_cbb_stats\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhead\u001b[49m())\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'head'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ed3d4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
